version: '3.8'

services:
  proxy_server:
    build: ./proxy_docker
    container_name: proxy_server
    ports:
      - "3128:3128"
    volumes:
      - squid-cache:/var/spool/squid
      - ./proxy_docker/squid.conf:/etc/squid/squid.conf

  ollama_container:
    build:
      context: ./ollama_docker
      args:
        http_proxy: "http://host.docker.internal:3128"
        https_proxy: "http://host.docker.internal:3128"
    container_name: ollama_container
    depends_on:
      - proxy_server
    volumes:
      # モデルデータを tainer ユーザーのホームに永続化
      - ./ollama:/home/tainer/.ollama
    environment:
      - http_proxy=http://proxy_server:3128
      - https_proxy=http://proxy_server:3128
      - HTTP_PROXY=http://proxy_server:3128
      - HTTPS_PROXY=http://proxy_server:3128
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=graphics,compute,utility
    ports:
      - "11434:11434"  # Ollama の API ポート
    tty: true
    stdin_open: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  squid-cache:
